/**
 * Reading Agent — AI-powered reading assistant with real thinking support
 *
 * Architecture:
 * 1. AI model decides which tools to call (not hardcoded rules)
 * 2. Thinking/reasoning comes from AI provider's API (not generated by us)
 * 3. Tool calls are executed completely before responding
 */
import type { AIConfig, Book, SemanticContext, Skill } from "@/types";
import {
  HumanMessage,
  SystemMessage,
  AIMessage,
} from "@langchain/core/messages";
import type { BaseMessage } from "@langchain/core/messages";
import { z } from "zod";
import { createChatModel } from "../llm-provider";
import { buildSystemPrompt } from "../system-prompt";
import type { ToolDefinition } from "../tools";

// --- Stream Event Types ---

export type AgentStreamEvent =
  | { type: "token"; content: string }
  | { type: "tool_call"; name: string; args: Record<string, unknown> }
  | { type: "tool_result"; name: string; result: unknown }
  | { type: "reasoning"; content: string; stepType: "thinking" | "planning" | "analyzing" | "deciding" }
  | { type: "citation"; citation: { id: string; chapterTitle: string; text: string; cfi: string } }
  | { type: "error"; error: string };

export interface ReadingAgentOptions {
  aiConfig: AIConfig;
  book: Book | null;
  semanticContext: SemanticContext | null;
  enabledSkills: Skill[];
  isVectorized: boolean;
  deepThinking?: boolean;
}

function buildSystemPromptForAgent(book: Book | null, semanticContext: SemanticContext | null): string {
  const parts: string[] = [
    "你是一个专业的阅读助手，帮助用户理解和分析书籍内容。",
    "",
    "## 工作原则",
    "1. 在回答问题前，先思考需要哪些信息",
    "2. 使用工具获取必要的上下文和内容",
    "3. 基于获取的信息给出准确、有深度的回答",
    "4. 如果需要更多信息，继续调用工具",
    "",
  ];

  if (book) {
    parts.push("## 当前书籍");
    parts.push(`书名: ${book.meta.title}`);
    if (book.meta.author) parts.push(`作者: ${book.meta.author}`);
    parts.push("");
  }

  if (semanticContext) {
    parts.push("## 当前阅读上下文");
    if (semanticContext.currentChapter) {
      parts.push(`当前章节: ${semanticContext.currentChapter}`);
    }
    if (semanticContext.surroundingText) {
      parts.push(`周围文本: ${semanticContext.surroundingText.slice(0, 500)}...`);
    }
    parts.push("");
  }

  parts.push("## 可用工具");
  parts.push("- getCurrentChapter: 获取当前章节信息");
  parts.push("- getSelection: 获取选中文本");
  parts.push("- getReadingProgress: 获取阅读进度");
  parts.push("- getRecentHighlights: 获取最近标注");
  parts.push("- getSurroundingContext: 获取周围上下文");
  parts.push("");
  parts.push("请根据用户的问题，选择合适的工具获取信息，然后给出回答。");

  return parts.join("\n");
}

// --- Tool Executor ---

async function executeTool(
  tool: ToolDefinition,
  args: Record<string, unknown>
): Promise<unknown> {
  try {
    return await tool.execute(args);
  } catch (error) {
    return {
      error: error instanceof Error ? error.message : String(error),
    };
  }
}

// --- Main Agent Function ---

export async function* streamReadingAgent(
  options: ReadingAgentOptions,
  userInput: string,
  history: Array<{ role: "user" | "assistant"; content: string }> = [],
): AsyncGenerator<AgentStreamEvent> {
  const { aiConfig, book, semanticContext, deepThinking } = options;

  try {
    // Create chat model
    const model = await createChatModel(aiConfig, {
      temperature: deepThinking ? 0.3 : 0.7,
      maxTokens: aiConfig.maxTokens,
      streaming: true,
    });

    // Import tools dynamically to avoid circular dependencies
    const { getContextTools } = await import("../context-tools");
    const tools = getContextTools(book?.id || "");
    const toolMap = new Map<string, ToolDefinition>();
    
    for (const tool of tools) {
      toolMap.set(tool.name, tool);
    }

    // Build messages
    const systemPrompt = buildSystemPromptForAgent(book, semanticContext);
    const messages: BaseMessage[] = [
      new SystemMessage(systemPrompt),
      ...history.map((h) =>
        h.role === "user" ? new HumanMessage(h.content) : new AIMessage(h.content)
      ),
      new HumanMessage(userInput),
    ];

    // Convert tools to LangChain format
    const { DynamicStructuredTool } = await import("@langchain/core/tools");
    const langChainTools = Array.from(toolMap.values()).map((tool) => {
      const schema = z.object({});
      return new DynamicStructuredTool({
        name: tool.name,
        description: tool.description,
        schema,
        func: async (input) => {
          return JSON.stringify(await executeTool(tool, input as Record<string, unknown>));
        },
      });
    });

    // Bind tools to model
    const modelWithTools = model.bindTools?.(langChainTools) ?? model;

    // First call - let AI decide if it needs tools
    let response = await modelWithTools.invoke(messages);
    
    // Track tool calls and results
    const toolMessages: BaseMessage[] = [];
    let iterationCount = 0;
    const maxIterations = 5;

    // Process tool calls in a loop
    while (response.tool_calls && response.tool_calls.length > 0 && iterationCount < maxIterations) {
      iterationCount++;

      // Process each tool call
      for (const toolCall of response.tool_calls) {
        const toolName = toolCall.name;
        const toolArgs = toolCall.args as Record<string, unknown>;
        const tool = toolMap.get(toolName);

        // Yield tool_call event
        yield { type: "tool_call", name: toolName, args: toolArgs };

        if (tool) {
          const result = await executeTool(tool, toolArgs);
          
          // Yield tool_result event
          yield { type: "tool_result", name: toolName, result };

          // Add tool result to messages
          toolMessages.push(
            new AIMessage({
              content: "",
              tool_calls: [{ 
                name: toolName, 
                args: toolArgs, 
                id: toolCall.id || `${toolName}-${Date.now()}` 
              }],
            })
          );
          
          toolMessages.push(
            new HumanMessage({
              content: JSON.stringify(result),
              name: toolName,
            }) as any
          );
        }
      }

      // Continue conversation with tool results
      const allMessages = [...messages, response, ...toolMessages];
      response = await modelWithTools.invoke(allMessages);
    }

    // Final streaming response
    if (response.content) {
      const content = typeof response.content === "string" 
        ? response.content 
        : JSON.stringify(response.content);
      
      // Simulate streaming by yielding chunks
      const chunkSize = 10;
      for (let i = 0; i < content.length; i += chunkSize) {
        yield { type: "token", content: content.slice(i, i + chunkSize) };
      }
    }

  } catch (error) {
    yield { type: "error", error: error instanceof Error ? error.message : String(error) };
  }
}

// --- Legacy exports for compatibility ---

export { buildSystemPrompt };
